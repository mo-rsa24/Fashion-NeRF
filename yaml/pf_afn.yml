debug: 0

# ========================= Training intention
question: 'Training PF_AFN to composite clothing on individuals'
impact: 'Low-resolution VITON for parser-free networks allowing real-time inference'
intent: 'Use original PF_AFN checkpoints for Rail data.' # What is the intent of the research
what_does_it_have: 'Parser Based warping trained on Original data'
rail_data: 'Contains 8 Unique Individual-Clothing Pairs'


# ========================= Run Hyperparameters
run_number: 1
experiment_number: 1
experiment_run: "experiment_{}/run_{}"
run_from_number: 1
experiment_from_number: 1
experiment_from_run: "experiment_{}/run_{}"



# ========================= Machine Hyperparameters
res: "low_res"
load_last_step: False
device: 1
VITON_Type: "Parser_Free"
VITON_selection_dir: "VITON/{}/{}"
wandb_name: wandb_name
cuda: true
run_wandb: True
viton_batch_size: 8

# ========================= VITON dataset
dataset_name: "Original"
low_res_viton_dataset_name: "VITON-Clean"

# ========================= VITON information
VITON_Model: "PB_Warp"
VITON_Name: "PF_AFN"
datamode: "train"
isTrain: True


# ========================= Directory
rail_dir: "data/VITON/{}/processed/{}/{}"
original_dir: "data/VITON/{}/processed/{}/{}"
root_dir: "/home-mscluster/mmolefe/Playground/Synthesising Virtual Fashion Try-On with Neural Radiance Fields/Fashion-SuperNeRF"
# root_dir: '/mnt/data/home/molefe/Playground/Synthesising Virtual Fashion Try-On with Neural Radiance Fields/Fashion-NeRF'
model_dir: "VITON/Parser_Free/PF_AFN/{}"
checkpoint_root_dir: "/gluster/mmolefe"
dataset_root_dir: "/datasets/mmolefe"
tensorboard_dir: "./tensorboard/{}/{}"
results_dir: "./results/{}/{}"


# ================================= PB_Gen ================================= 
pb_gen_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_gen_save_step_checkpoint: "pb_gen_%06d.pth"
pb_gen_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_gen_load_step_checkpoint: "pb_gen_%06d.pth"
pb_gen_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_gen_save_final_checkpoint: "gen_model_final.pth"
pb_gen_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_gen_load_final_checkpoint: "gen_model_final.pth"

# ================================= PF_Gen ================================= 
pf_gen_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_gen_save_step_checkpoint: "pf_gen_%06d.pth"
pf_gen_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_gen_load_step_checkpoint: "pf_gen_%06d.pth"
pf_gen_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_gen_save_final_checkpoint: "gen_model_final.pth"
pf_gen_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_gen_load_final_checkpoint: "gen_model_final.pth"

# ================================= PB_Warp ================================= 
pb_warp_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_warp_save_step_checkpoint: "pb_warp_%06d.pth"
pb_warp_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_warp_load_step_checkpoint: "pb_warp_%06d.pth"
pb_warp_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_warp_save_final_checkpoint: "warp_model_final.pth"
pb_warp_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_warp_load_final_checkpoint: "warp_model_final.pth"

# ================================= PF_Warp ================================= 
pf_warp_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_warp_save_step_checkpoint: "pf_warp_%06d.pth"
pf_warp_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_warp_load_step_checkpoint: "pf_warp_%06d.pth"
pf_warp_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_warp_save_final_checkpoint: "warp_model_final.pth"
pf_warp_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_warp_load_final_checkpoint: "warp_model_final.pth"


# =====================  Sweep Hyperparameters
lambda_loss_second_smooth: 3
lambda_loss_vgg: 0.3
lambda_loss_vgg_skin: 0.3
lambda_loss_edge: 2
lambda_loss_smooth: 0.01
lambda_loss_l1: 6
lambda_loss_l1_skin: 30
lambda_loss_l1_mask: 1
lambda_bg_loss_l1: 5
lambda_bg_loss_vgg: 5
lambda_loss_warp: 0.4
lambda_loss_gen: 1.0
lambda_cond_sup_loss: 0.04
lambda_warp_sup_loss: 0.04
align_corners: false
optimizer: Adam
netG: global
ngf: 64
beta1: 0.5
ndf: 64
n_downsample_global: 4
n_blocks_global: 4
no_ganFeat_loss: False
no_vgg_loss: False
no_lsgan: False
n_blocks_local: 3
no_flip: False
n_layers_D: 3
num_D: 2
local_rank: 0
pool_size: 0
n_local_enhancers: 1
niter_fix_global: 0
epsilon: 0.001
momentum: 0.9
tv_weight: 0.1
radius: 5
grid_size: 5
lr: 0.00005
pb_gen_lr: 0.2
resize_or_crop: scale_width # [resize_and_crop|crop|scale_width|scale_width_and_crop]


# ===================== Input/Output Hyperparameters
input_nc: 3
output_nc: 3
label_nc: 20
loadSize: 512
fineSize: 512
# ===================== Experiment Hyperparameters
niter: 50 # opt.niter + opt.niter_decay = total number of epochs
niter_decay: 50
gen_load_from_model: Original
warp_load_from_model: Rail
resume: false
validate: True
serial_batches: False 
shuffle: False
segment_anything: False
clip_warping: True
seed: 1

# ===================== Logging Hyperparameters
display_count: 10 # Frequency Of Saving Training Results As Images & Graphs
print_step: 10 # Frequency Of Print Training Results On Screen'
save_period: 10 # Frequency Of Saving Checkpoints At The End Of Epochs
continue_train: False