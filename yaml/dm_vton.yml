debug: 0
sweeps: 0
run_wandb: 0

# ========================= Training intention
intent: 'Use original DM_VTON checkpoints for Rail data.' # What is the intent of the research
what_does_it_have: 'Parser Based warping trained on Original data'
rail_data: 'Contains 8 Unique Individual-Clothing Pairs'


# ========================= Run Hyperparameters
run_number: 1
experiment_number: 1
experiment_run: "experiment_{}/run_{}"
run_from_number: 1
experiment_from_number: 1
experiment_from_run: "experiment_{}/run_{}"



# ========================= Machine Hyperparameters
res: "low_res"
load_last_step: False
device: 1
VITON_Type: "Parser_Free"
VITON_selection_dir: "VITON/{}/{}"
wandb_name: wandb_name
cuda: true
run_wandb: True
viton_batch_size: 8

# ========================= VITON dataset
dataset_name: "Original"
low_res_viton_dataset_name: "VITON-Clean"

# ========================= VITON information
VITON_Model: "PB_Warp"
VITON_Name: "DM_VTON"
datamode: "train"


# ========================= Directory
rail_dir: "data/VITON/{}/processed/{}/{}"
original_dir: "data/VITON/{}/processed/{}/{}"
root_dir: "/home-mscluster/mmolefe/Playground/Synthesising Virtual Fashion Try-On with Neural Radiance Fields/Fashion-SuperNeRF"
model_dir: "VITON/Parser_Free/DM_VTON/{}"
checkpoint_root_dir: "/gluster/mmolefe"
dataset_root_dir: "/datasets/mmolefe"
tensorboard_dir: "./tensorboard/{}/{}"
results_dir: "./results/{}/{}"


# ================================= PB_Gen ================================= 
pb_gen_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_gen_save_step_checkpoint: "pb_gen_%06d.pt"
pb_gen_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_gen_load_step_checkpoint: "pb_gen_%06d.pt"
pb_gen_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_gen_save_final_checkpoint: "pb_gen.pt"
pb_gen_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_gen_load_final_checkpoint: "pb_gen.pt"

# ================================= PF_Gen ================================= 
pf_gen_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_gen_save_step_checkpoint: "pf_gen_%06d.pt"
pf_gen_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_gen_load_step_checkpoint: "pf_gen_%06d.pt"
pf_gen_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_gen_save_final_checkpoint: "pf_gen.pt"
pf_gen_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_gen_load_final_checkpoint: "pf_gen.pt"

# ================================= PB_Warp ================================= 
pb_warp_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_warp_save_step_checkpoint: "pb_warp_%06d.pt"
pb_warp_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pb_warp_load_step_checkpoint: "pb_warp_%06d.pt"
pb_warp_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_warp_save_final_checkpoint: "pb_warp.pt"
pb_warp_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pb_warp_load_final_checkpoint: "pb_warp.pt"

# ================================= PF_Warp ================================= 
pf_warp_save_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_warp_save_step_checkpoint: "pf_warp_%06d.pt"
pf_warp_load_step_checkpoint_dir: "/checkpoints/{}/{}/steps"
pf_warp_load_step_checkpoint: "pf_warp_%06d.pt"
pf_warp_save_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_warp_save_final_checkpoint: "pf_warp.pt"
pf_warp_load_final_checkpoint_dir: "/checkpoints/{}/{}"
pf_warp_load_final_checkpoint: "pf_warp.pt"


# =====================  Sweep Hyperparameters
lambda_loss_second_smooth: 3
lambda_loss_vgg: 0.3
question: 'Training pb_gen to composite clothing on individuals'
impact: 'Low-resolution VITON for parser-free networks allowing real-time inference'
lambda_loss_edge: 2
lambda_loss_smooth: 0.01
lambda_loss_l1: 6
lambda_bg_loss_l1: 5
lambda_loss_warp: 0.4
lambda_loss_gen: 1.0
lambda_cond_sup_loss: 0.04
lambda_warp_sup_loss: 0.04
align_corners: false
optimizer: Adam
epsilon: 0.001
momentum: 0.9
lr: 0.00005
pb_gen_lr: 0.2

# ===================== Experiment Hyperparameters
niter: 50 # opt.niter + opt.niter_decay = total number of epochs
niter_decay: 50
val_count: 100
gen_load_from_model: Original
warp_load_from_model: Rail
resume: false
validate: True





# ===================== Logging Hyperparameters
display_count: 10 # Frequency Of Saving Training Results As Images & Graphs
print_step: 10 # Frequency Of Print Training Results On Screen'
save_period: 10 # Frequency Of Saving Checkpoints At The End Of Epochs
continue_train: False